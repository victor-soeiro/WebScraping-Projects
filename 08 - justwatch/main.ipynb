{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5178c39c-938b-4072-bac3-99c97cb31a1d",
   "metadata": {},
   "source": [
    "## **JustWatch - Webscraping Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222019c-bd32-422e-862c-9e65b8be4aaf",
   "metadata": {},
   "source": [
    "### **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33bb20c-2636-4019-9987-484e7653e09d",
   "metadata": {},
   "source": [
    "**JustWatch** website uses ajax to consumes their API using **GraphQL queries**. The data returns as a **JSON** file. To get the data all we need is the **requests** package. It will not be necessary any other package.\n",
    "\n",
    "> **If you wanna replicate, maybe you need to install some of the packages with PIP command.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea672dc8-0d16-4ae9-be08-bc5b501c8ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a93d41-97db-42a9-8a0e-a3d3d0ac5947",
   "metadata": {},
   "source": [
    "To get the data we need the **reference code** of the streaming to pass as a **GraphQL variable**. I collected an amount of great **streamings** references codes and parses as a **dictionary**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c1e8be0-e047-4f94-ad71-656d9e8d2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamings = dict(\n",
    "    amazon='amp',\n",
    "    disney='dnp',\n",
    "    darkmatter='dkm',\n",
    "    rakuten_viki='vik',\n",
    "    hbo='hbm',\n",
    "    netflix='nfx',\n",
    "    hulu='hlu',\n",
    "    paramount='pmp',\n",
    "    funimation='fmn',\n",
    "    crunchyroll='cru',\n",
    "    starz='stz',\n",
    "    appletv='atp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5507df03-561c-4404-8566-68c5de93bcfa",
   "metadata": {},
   "source": [
    "Their **API** uses only one **endpoint** to get the queries. So, we need just change the **parameters** and the **query** to collect the streamings data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f2d595-d645-4503-bf3a-bdd6d2583008",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://apis.justwatch.com/graphql\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc86a0-6247-4e3a-b29f-53e605197af2",
   "metadata": {},
   "source": [
    "The website **prevents** a robot to get their data **without** specifying a **User-Agent**. Let's create our request headers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43fab464-0202-4ba4-ad53-5b59254eb800",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.41 Safari/537.36 Edg/101.0.1210.32\",\n",
    "    \"accept-encoding\": \"gzip, deflate, br\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41cd3ec-391c-4ee8-bda1-071d58aeb10b",
   "metadata": {},
   "source": [
    "This project **doesn't aims to explain how the query works, or how it was modified**, but the post data and the query was stored on a file to save us time. \n",
    "\n",
    "Check the following files:\n",
    "\n",
    "- **postData.json**\n",
    "- **query.graphql**\n",
    "\n",
    "Let's **open** those files and **saves to a variable** to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0143e6c-e6a2-4e6c-8c00-387fccf2bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('src/postData.json', 'r', encoding='utf-8') as file:\n",
    "    post_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d344b01b-3a86-4fa0-bf86-dba3d0c04f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('src/query.graphql', 'r', encoding='utf-8') as file:\n",
    "    query = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cf4ad66-6fb4-4ecb-be91-9cab5fc45f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_data['query'] = query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0e5d3-0d69-4bf0-ad63-1d77444986a1",
   "metadata": {},
   "source": [
    "The post data **not specify** which **stream** we will get the data. Let's encapsulate in a function this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3f298f1-4ad6-4948-b616-dd671e617856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_streaming(key: str):\n",
    "    \"\"\" Set the streaming on query variables. \"\"\"\n",
    "    \n",
    "    post_data['variables']['popularTitlesFilter']['packages'] = [streamings[key]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf7e8d-0e0e-4648-857a-6abac1676844",
   "metadata": {},
   "source": [
    "Some streamings has **over 3k movies and shows**. The query **only returns** a total of **1960 results**, which is not enough to collect all data. \n",
    "\n",
    "To get through this, we will use the **released year filter** to create a **cluster** of items with **below 1960 items**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b9a6a29-8224-451a-b8b0-dcb8502df737",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [1899, 1950, 1980, 1990, 2000, 2010, 2012, 2014, 2016, 2018, 2020, 2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baeb21a-9438-454a-aeb1-91b54be0959e",
   "metadata": {},
   "source": [
    "Let's create a **loop function** to get **all titles available** on a given **streaming**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05737a87-6bca-420f-b655-3e1ea034d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles(streaming: str, cursor: str = None, titles: list = None, start: bool = True):\n",
    "    \"\"\" Get all titles available of a streaming. \"\"\"\n",
    "    \n",
    "    if not titles:\n",
    "        titles = []\n",
    "    \n",
    "    if cursor and not start:\n",
    "        post_data['variables']['popularAfterCursor'] = cursor\n",
    "    else:\n",
    "        post_data['variables']['popularAfterCursor'] = \"\"\n",
    "    \n",
    "    set_streaming(streaming)\n",
    "    req = requests.post(url, data=json.dumps(post_data), headers=headers)\n",
    "    if req.status_code != 200:\n",
    "        raise requests.ConnectionError('connection failed')\n",
    "    \n",
    "    results = req.json()['data']['popularTitles']\n",
    "    titles.extend(results['edges'])   \n",
    "       \n",
    "    if results['pageInfo']['hasNextPage']:\n",
    "        cursor = results['pageInfo']['endCursor']\n",
    "        get_titles(streaming=streaming, cursor=cursor, titles=titles, start=False)\n",
    "    \n",
    "    return titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e0dde-4dcd-4fec-9f1e-87e3de4d7b20",
   "metadata": {},
   "source": [
    "The returned data is well formatted, but it's nested. Let's **parse** the data to a **unique dictionary** containing the correctly fields names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2994c41d-768d-4f92-b0fd-f3e530ce9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_title_content(title: dict):\n",
    "    \"\"\" Parse the title content to a dictionary. \"\"\"\n",
    "    \n",
    "    content = {}\n",
    "    \n",
    "    title = title['node']\n",
    "    content['id'] = title['id']\n",
    "    content['title'] = title['content']['title']\n",
    "    content['type'] = title['objectType']\n",
    "    content['description'] = title['content']['shortDescription']\n",
    "    content['release_year'] = title['content']['originalReleaseYear']\n",
    "    content['age_certification'] = title['content']['ageCertification']\n",
    "    content['runtime'] = title['content']['runtime']\n",
    "    content['genres'] = [i['technicalName'] for i in title['content']['genres']]\n",
    "    content['production_countries'] = title['content']['productionCountries']\n",
    "    content['seasons'] = title.get('totalSeasonCount', None)\n",
    "    content['imdb_id'] = title['content']['externalIds']['imdbId']\n",
    "    content['imdb_score'] = title['content']['scoring']['imdbScore']\n",
    "    content['imdb_votes'] = title['content']['scoring']['imdbVotes']\n",
    "    content['tmdb_popularity'] = title['content']['scoring']['tmdbPopularity']\n",
    "    content['tmdb_score'] = title['content']['scoring']['tmdbScore']\n",
    "    \n",
    "    credits = [\n",
    "        {\n",
    "            'person_id': i['personId'],\n",
    "            'id': content['id'],\n",
    "            'name': i['name'],\n",
    "            'character': i['characterName'],\n",
    "            'role': i['role']\n",
    "        } for i in title['content']['credits']\n",
    "    ]\n",
    "    \n",
    "    return content, credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5113cfcc-f1e8-4642-8080-82efde1a0460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_save_data(data: list, save: bool = True, path: str = ''):\n",
    "    \"\"\" Parse a list of titles and save it to a file. \"\"\"\n",
    "    \n",
    "    titles, credits = [], []\n",
    "    for d in data:\n",
    "        t, c = parse_title_content(d)\n",
    "        titles.append(t)\n",
    "        credits.extend(c)\n",
    "    \n",
    "    if save:\n",
    "        titles_df = pd.DataFrame(titles)\n",
    "        titles_df.to_csv(path+'titles.csv', index=False)\n",
    "\n",
    "        credits_df = pd.DataFrame(credits)\n",
    "        credits_df.to_csv(path+'credits.csv', index=False)\n",
    "\n",
    "    return titles, credits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b6102b-b1d3-40de-beea-a938dafcd03b",
   "metadata": {},
   "source": [
    "All the functions are defined, let's group together to get **all titles available on a streaming**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61294572-0877-4e69-b95e-8d6b1c33ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_titles_by_streaming(streaming: str, save: bool = True, path: str = ''):\n",
    "    \"\"\" Get all titles available on a given streaming. \"\"\"\n",
    "    raw = []\n",
    "    for i in range(len(clusters) - 1):\n",
    "        filter_range = {'min': clusters[i]+1, 'max': clusters[i+1]}\n",
    "        \n",
    "        post_data['variables']['popularTitlesFilter']['releaseYear'] = filter_range  # Set the filter\n",
    "        \n",
    "        cluster_titles = get_titles(streaming=streaming)\n",
    "        raw.extend(cluster_titles)\n",
    "    \n",
    "    if save:\n",
    "        file_path = f'{path}/{streaming}/'\n",
    "        if not os.path.exists(file_path):\n",
    "            os.mkdir(file_path)\n",
    "            \n",
    "    titles, credits = parse_and_save_data(data=raw, save=save, path=file_path)\n",
    "    \n",
    "    return titles, credits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb3eb23-5ba5-45fb-808d-0c95d3e7e6e9",
   "metadata": {},
   "source": [
    "And now, a function to get **all titles** from **all the streamings**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69b72c0f-c64b-48ef-95a5-e097da9c37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_titles(save: bool = True, path:str = ''):\n",
    "    \"\"\" Get all titles available on the available streamings. \"\"\"\n",
    "    \n",
    "    all_titles = {}\n",
    "    for key in tqdm(streamings.keys()):\n",
    "        titles, credits = get_all_titles_by_streaming(streaming=key, save=save, path=path)\n",
    "        all_titles[key] = {'titles': titles, 'credits': credits}\n",
    "    \n",
    "    return all_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ca4a38-0dab-4801-8c8a-d2eb751c986c",
   "metadata": {},
   "source": [
    "**Let's save it!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a6b7a99-959d-4f68-8616-6a3dbf49e2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5083b3796e43d0898331badf1d3639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5806"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_all_titles(save=True, path='data')\n",
    "len(data['netflix']['titles'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
