{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2623484e-9224-4c6c-9d4d-7fb2d1a4da8c",
   "metadata": {},
   "source": [
    "## **Journal of Machine Learning Research (JMLR) - WebScraping Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab3a9bc-8a2b-4882-ab19-ca0b359c94df",
   "metadata": {},
   "source": [
    "> **Disclaimer:** This is a personal project to practice webscraping skills and exploratory data analysis. I do not recommend to use for other purposes. Use it at your own risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51c2dc2-ad0e-40c2-a2fb-cf6412c444d4",
   "metadata": {},
   "source": [
    "### **Libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaceb9fd-eab0-4f29-bae8-e633ef063081",
   "metadata": {},
   "source": [
    "All volumes and papers of JMLR are on only one page. The scraping process will use only the main tools. \n",
    "\n",
    "> **If you wanna replicate, maybe you need to install some of the packages with PIP command.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5763269f-0e2d-4d68-8710-168818992f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34406368-cb27-451d-8a39-3b6013e5744d",
   "metadata": {},
   "source": [
    "### **Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c8942f-dfea-438a-9ed5-c0f4dc647dbf",
   "metadata": {},
   "source": [
    "Let's define the URL to request the volumes HTML page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a064d7e7-e23e-4ec0-9c25-dda9eec7f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.jmlr.org/papers/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b0f434-034c-44c7-a572-1d760c867c80",
   "metadata": {},
   "source": [
    "### **Volumes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35913397-220e-4c15-a68f-3d2d35dcb9f7",
   "metadata": {},
   "source": [
    "Let's start the extracting process of the volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b7f3440-5c0a-40f3-ab70-70c6af10e2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vols_req = requests.get(url)\n",
    "vols_req.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c9f16-9be3-4282-b017-5a58132b462b",
   "metadata": {},
   "source": [
    "Parsing the HTML to a BeautifulSoup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca01315-083d-460c-9316-253aa7fe88f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vols_soup = BeautifulSoup(vols_req.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3f4599-5dc9-49e7-bb68-250d9c901bd2",
   "metadata": {},
   "source": [
    "The volumes will be on a list to loop and scrape the papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d11299c6-cada-420e-9dab-242775d49915",
   "metadata": {},
   "outputs": [],
   "source": [
    "vols = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c0032b-85c2-4fdb-8915-f2f4bea8f556",
   "metadata": {},
   "source": [
    "The information it's stored on a *font* tag with a *volume* class. It's easy to scrape the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f3383c7-e09e-4c1b-ba22-7dd539daeafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = vols_soup.findAll('font', {'class': 'volume'})\n",
    "for i in content:\n",
    "    container = i.parent \n",
    "    href = container['href']\n",
    "    if 'papers' in href:\n",
    "        href = 'https://www.jmlr.org' + href\n",
    "    else:\n",
    "        href = url + href\n",
    "    \n",
    "    volume = i.text.strip()   \n",
    "    vols.append(dict(href=href, volume=volume))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7afcc5-2722-480e-8eae-399189e5c0dd",
   "metadata": {},
   "source": [
    "Let's check the last released volume!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7569d01a-b012-48d2-86d4-7f7473fc0afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'href': 'https://www.jmlr.org/papers/v23', 'volume': 'Volume 23'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vols[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cbd7fb-87a5-4979-a998-b4137c4789ec",
   "metadata": {},
   "source": [
    "### **Papers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73367d67-0080-4114-a9a8-ebcb1697a8cb",
   "metadata": {},
   "source": [
    "If one error occurs in the scraping process, we will lose all the progress. One of the possibilities is to write directly into a file, but it will be a heavy memory consumer. As we are dealing with a notebook, I will write the data in a dictionary, as the key is the volume, and the value it's the paper.\n",
    "\n",
    "Maybe it's not the best idea, but it will be enough for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13e4f038-0d12-4f4c-b36a-0d136347c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_per_volume = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2298390-6a9d-4fd9-8e0d-28e33c0d2173",
   "metadata": {},
   "source": [
    "Unfortunately, over the papers, the data are not distributed uniformly. We will need more steps to scrape all the data correctly. For each volume, it has a set of papers. Let's scrape each one of them and store them in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3a91e4e-d73c-41f1-9565-196fb9adc986",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5cea9aec5040d285ddcdcbb2fb87d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for v in tqdm(vols):\n",
    "    url = v['href']\n",
    "    volume = v['volume']\n",
    "    \n",
    "    if papers_per_volume.get(volume, []):\n",
    "        continue \n",
    "    \n",
    "    req = requests.get(url)\n",
    "    if req.status_code != 200:\n",
    "        raise requests.ConnectionError(f\"Connection Failed to {url}.\")\n",
    "    \n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "    \n",
    "    papers = []\n",
    "    papers_container = soup.findAll('dl')\n",
    "    for p in papers_container:        \n",
    "        dt = p.find('dt')\n",
    "        dd = p.find('dd')\n",
    "        \n",
    "        if dt.find('dd'):\n",
    "            title = list(dt.children)[0].text.strip()\n",
    "        else:\n",
    "            title = dt.text.strip()\n",
    "        \n",
    "        authors = dd.b.text.strip().split(', ')\n",
    "        \n",
    "        desc = dd.b.nextSibling.text.strip()        \n",
    "        year = desc.split(' ')[-1].replace('.', '')  \n",
    "        pages_string = desc[desc.find(\":\")+1:desc.rfind(\",\")]\n",
    "        pages_values = re.findall(r'[0-9]+', pages_string)\n",
    "        pages = int(pages_values[1]) - int(pages_values[0]) + 1\n",
    "                \n",
    "        code_string = dd.find(string='code')\n",
    "        if code_string:\n",
    "            code = code_string.parent['href']\n",
    "        else:\n",
    "            code = ''\n",
    "        \n",
    "        pdf = dd.find(string='pdf')\n",
    "        if pdf:\n",
    "            link = pdf.parent['href']\n",
    "        else:\n",
    "            link = dd.find(string='[pdf]').parent['href']\n",
    "        \n",
    "        if 'www' not in link:\n",
    "            link = 'https://www.jmlr.org' + link\n",
    "                \n",
    "        papers.append(dict(title=title, volume=volume, authors=authors, year=year, pages=pages, link=link, code=code))\n",
    "        \n",
    "    papers_per_volume[volume] = papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a438bdb5-5a4d-415a-8ed3-afc209a4121a",
   "metadata": {},
   "source": [
    "Let's see the first two papers of the first volume!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a0af719-c9bd-48ab-a496-5f580d0a50f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Learning with Mixtures of Trees',\n",
       "  'volume': 'Volume 1',\n",
       "  'authors': ['Marina Meila', 'Michael I. Jordan'],\n",
       "  'year': '2000',\n",
       "  'pages': 48,\n",
       "  'link': 'http://www.jmlr.org/papers/volume1/meila00a/meila00a.pdf',\n",
       "  'code': ''},\n",
       " {'title': 'Dependency Networks for Inference, Collaborative Filtering, and Data Visualization',\n",
       "  'volume': 'Volume 1',\n",
       "  'authors': ['David Heckerman',\n",
       "   'David Maxwell Chickering',\n",
       "   'Christopher Meek',\n",
       "   'Robert Rounthwaite',\n",
       "   'Carl Kadie'],\n",
       "  'year': '2000',\n",
       "  'pages': 27,\n",
       "  'link': 'http://www.jmlr.org/papers/volume1/heckerman00a/heckerman00a.pdf',\n",
       "  'code': ''}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_per_volume['Volume 1'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b5366-8f7a-4e37-a2fd-be6971c8877b",
   "metadata": {},
   "source": [
    "### **Save data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0619f4-fc65-4fa3-aec8-9f0ec33fc5bc",
   "metadata": {},
   "source": [
    "As the papers are per volume, let's group them all on a list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d08ec077-259d-4395-ae68-3a7615437496",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = []\n",
    "for p in papers_per_volume.values():\n",
    "    full_data.extend(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd81305a-33d9-459c-a5ad-4e0b09ea7bb6",
   "metadata": {},
   "source": [
    "Now, we can pass to a DataFrame and check the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64bf2efb-841c-4099-9bdc-00a2b49abbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>volume</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>pages</th>\n",
       "      <th>link</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joint Estimation and Inference for Data Integr...</td>\n",
       "      <td>Volume 23</td>\n",
       "      <td>[Subhabrata Majumdar, George Michailidis]</td>\n",
       "      <td>2022</td>\n",
       "      <td>53</td>\n",
       "      <td>https://www.jmlr.org/papers/volume23/18-131/18...</td>\n",
       "      <td>https://github.com/GeorgeMichailidis/JMMLE_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Debiased  Distributed Learning for Sparse Part...</td>\n",
       "      <td>Volume 23</td>\n",
       "      <td>[Shaogao Lv, Heng Lian]</td>\n",
       "      <td>2022</td>\n",
       "      <td>32</td>\n",
       "      <td>https://www.jmlr.org/papers/volume23/18-467/18...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recovering shared structure from multiple netw...</td>\n",
       "      <td>Volume 23</td>\n",
       "      <td>[Keith Levin, Asad Lodhia, Elizaveta Levina]</td>\n",
       "      <td>2022</td>\n",
       "      <td>48</td>\n",
       "      <td>https://www.jmlr.org/papers/volume23/19-1056/1...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exploiting locality in high-dimensional Factor...</td>\n",
       "      <td>Volume 23</td>\n",
       "      <td>[Lorenzo Rimella, Nick Whiteley]</td>\n",
       "      <td>2022</td>\n",
       "      <td>34</td>\n",
       "      <td>https://www.jmlr.org/papers/volume23/19-267/19...</td>\n",
       "      <td>https://github.com/LorenzoRimella/GraphFilter-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Empirical Risk Minimization under Random Censo...</td>\n",
       "      <td>Volume 23</td>\n",
       "      <td>[Guillaume Ausset, Stephan ClÃ©menÃ§on, FranÃ§...</td>\n",
       "      <td>2022</td>\n",
       "      <td>59</td>\n",
       "      <td>https://www.jmlr.org/papers/volume23/19-450/19...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     volume  \\\n",
       "0  Joint Estimation and Inference for Data Integr...  Volume 23   \n",
       "1  Debiased  Distributed Learning for Sparse Part...  Volume 23   \n",
       "2  Recovering shared structure from multiple netw...  Volume 23   \n",
       "3  Exploiting locality in high-dimensional Factor...  Volume 23   \n",
       "4  Empirical Risk Minimization under Random Censo...  Volume 23   \n",
       "\n",
       "                                             authors  year  pages  \\\n",
       "0          [Subhabrata Majumdar, George Michailidis]  2022     53   \n",
       "1                            [Shaogao Lv, Heng Lian]  2022     32   \n",
       "2       [Keith Levin, Asad Lodhia, Elizaveta Levina]  2022     48   \n",
       "3                   [Lorenzo Rimella, Nick Whiteley]  2022     34   \n",
       "4  [Guillaume Ausset, Stephan ClÃ©menÃ§on, FranÃ§...  2022     59   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.jmlr.org/papers/volume23/18-131/18...   \n",
       "1  https://www.jmlr.org/papers/volume23/18-467/18...   \n",
       "2  https://www.jmlr.org/papers/volume23/19-1056/1...   \n",
       "3  https://www.jmlr.org/papers/volume23/19-267/19...   \n",
       "4  https://www.jmlr.org/papers/volume23/19-450/19...   \n",
       "\n",
       "                                                code  \n",
       "0    https://github.com/GeorgeMichailidis/JMMLE_code  \n",
       "1                                                     \n",
       "2                                                     \n",
       "3  https://github.com/LorenzoRimella/GraphFilter-...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(full_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834b2580-37f1-4d97-a03f-003c87369060",
   "metadata": {},
   "source": [
    "And finally, let's save the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71432428-9326-473a-9862-5a76f1ba9eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
